{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               'ü•∫'\n",
    "                               'üü•'\n",
    "                               'ü§¶'\n",
    "                               'ü§Æ'\n",
    "                               'ü§©'\n",
    "                               'ü§õ'\n",
    "                               'ü§≤'\n",
    "                               'ü§¨'\n",
    "                               'ü§î'\n",
    "                               'ü§£'\n",
    "                               'ü§∑‚Äç'\n",
    "                               'ü§™'\n",
    "                               'ü•∞'\n",
    "                               'ü§Ø'\n",
    "                               'ü•á'\n",
    "                               'ü•â'\n",
    "                               'ü•Ä'\n",
    "                               'ü§≠'\n",
    "                               'ü•≥'\n",
    "                               'üßê'\n",
    "                               'ü§ò'\n",
    "                               'ü§ö'\n",
    "                               'ü§ì'\n",
    "                               '‚è∞'\n",
    "                               'ü•≤'\n",
    "                               'ü§ó'\n",
    "                               'üßë'\n",
    "                               'ü¶≥'\n",
    "                               '‚ù§Ô∏è'\n",
    "                               'üßø'\n",
    "                               'ü§ï'\n",
    "                               'ü§ù'\n",
    "                               ': )'\n",
    "                               ' ( '\n",
    "                               ') '\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuations(text):\n",
    "    punctuations = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'\n",
    "    pattern = r\"[{}]\".format(punctuations) \n",
    "    text = re.sub(pattern, ' ', text) \n",
    "    text = text.replace('...', ' ') \n",
    "    text = text.replace('‚Äú', ' ') \n",
    "    text = text.replace('‚Äù', ' ')  \n",
    "    text = text.replace('‚Äô', ' ')  \n",
    "    text = text.replace('‚Äú', ' ')\n",
    "    text = text.replace('@', ' ')\n",
    "    text = text.replace('#', ' ')  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'raw text/'\n",
    "new_folder_path = 'sooooon/'\n",
    "\n",
    "\n",
    "for i in os.listdir(f_path):\n",
    "\n",
    "\n",
    "    with open(f'raw text/{i}', 'r',encoding='utf-8') as f:\n",
    "        metin = f.read()\n",
    "\n",
    "\n",
    "    metin = re.sub(r'http\\S+', ' ', metin)  #remove all links\n",
    "    metin=remove_emoji(text=metin)#remove all emojis \n",
    "    metin=remove_punctuations(text=metin) #remove puncs\n",
    "\n",
    "\n",
    "\n",
    "    # Yeni metin i√ßeriƒüini dosyaya yaz\n",
    "    cleaned_file_path = os.path.join(new_folder_path, f'{i}')\n",
    "    with open(cleaned_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(metin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_csv(file_name):\n",
    "    # TXT dosyasƒ±nƒ± DataFrame olarak oku\n",
    "\n",
    "    df = pd.read_table(file_name, header=None, names=['tweet'])\n",
    "\n",
    "    csv_path = file_name.replace('.txt', '.csv')\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='sooooon'\n",
    "for i in os.listdir(file_name):\n",
    "    if i.startswith(\"CHP\"):\n",
    "        txt_to_csv(f'sooooon/{i}')\n",
    "    if i.startswith(\"AKP\"):\n",
    "        txt_to_csv(f'sooooon/{i}')\n",
    "    if i.startswith(\"HDP\"):\n",
    "        txt_to_csv(f'sooooon/{i}')\n",
    "    if i.startswith(\"IYIP\"):\n",
    "        txt_to_csv(f'sooooon/{i}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('islevsiz.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = [word.strip() for word in file.readlines()]\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    clean_words = [word for word in words if word.lower() not in stopwords]\n",
    "    return ' '.join(clean_words)\n",
    "\n",
    "\n",
    "folder_path = 'sooooon/'\n",
    "new_folder_path = 'son2/'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['tweet'] = df['tweet'].apply(remove_stopwords)\n",
    "        normalized_file_path = os.path.join(new_folder_path, f'{filename}')\n",
    "\n",
    "        df.to_csv(normalized_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10122\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'son2/'\n",
    "df_chp = []\n",
    "df_akp=[]\n",
    "df_iyip=[]\n",
    "df_hdp=[]\n",
    "\n",
    "\n",
    "for i in os.listdir(folder_path):\n",
    "    if i.startswith(\"CHP\"):\n",
    "        file_path = os.path.join(folder_path, i)\n",
    "        dfchp = pd.read_csv(file_path)\n",
    "        df_chp.append(dfchp)\n",
    "    elif i.startswith(\"AKP\"):\n",
    "        file_path = os.path.join(folder_path, i)\n",
    "        dfakp = pd.read_csv(file_path)\n",
    "        df_akp.append(dfakp)    \n",
    "    elif i.startswith(\"IYIP\"):\n",
    "        file_path = os.path.join(folder_path, i)\n",
    "        dfiyip = pd.read_csv(file_path)\n",
    "        df_iyip.append(dfiyip)\n",
    "    else:\n",
    "        file_path = os.path.join(folder_path, i)\n",
    "        dfhdp = pd.read_csv(file_path)\n",
    "        df_hdp.append(dfhdp) \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "chpscombined_df = pd.concat(df_chp,ignore_index=True)\n",
    "akpscombined_df = pd.concat(df_akp,ignore_index=True)\n",
    "hdpscombined_df = pd.concat(df_hdp,ignore_index=True)\n",
    "iyipscombined_df = pd.concat(df_iyip,ignore_index=True)\n",
    "print(len(akpscombined_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10122\n",
      "10122\n",
      "4238\n",
      "6562\n"
     ]
    }
   ],
   "source": [
    "print(len(akpscombined_df))\n",
    "print(len(chpscombined_df))\n",
    "print(len(hdpscombined_df))\n",
    "print(len(iyipscombined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ƒ∞Yƒ∞ Parti mizin deƒüerli ƒ∞stanbul 2 B√∂lge Te≈üki...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKP KORKUYOR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bek√ßi hƒ±rsƒ±z kovalƒ±yormu≈ü‚Ä¶ Bak Allahƒ±n i≈üine‚Ä¶ ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D√ú≈û√úNCELER KUR≈ûUN GE√áƒ∞RMEZ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Halk TV ƒ∞smail K√º√ß√ºkkaya sorularƒ±nƒ± yanƒ±tlƒ±yorum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6557</th>\n",
       "      <td>d√ºnya size kalmaz YiyinEfendilerYiyin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>H√ºr D√º≈ü√ºnce Hareketi y√∂netimi Gelecek Partisi ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>GeldikleriGibiGidecekler</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6560</th>\n",
       "      <td>BeyazBulu≈üma</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>8Mart</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6562 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "0     ƒ∞Yƒ∞ Parti mizin deƒüerli ƒ∞stanbul 2 B√∂lge Te≈üki...     2\n",
       "1                                          AKP KORKUYOR     2\n",
       "2     Bek√ßi hƒ±rsƒ±z kovalƒ±yormu≈ü‚Ä¶ Bak Allahƒ±n i≈üine‚Ä¶ ...     2\n",
       "3                            D√ú≈û√úNCELER KUR≈ûUN GE√áƒ∞RMEZ     2\n",
       "4      Halk TV ƒ∞smail K√º√ß√ºkkaya sorularƒ±nƒ± yanƒ±tlƒ±yorum     2\n",
       "...                                                 ...   ...\n",
       "6557              d√ºnya size kalmaz YiyinEfendilerYiyin     2\n",
       "6558  H√ºr D√º≈ü√ºnce Hareketi y√∂netimi Gelecek Partisi ...     2\n",
       "6559                           GeldikleriGibiGidecekler     2\n",
       "6560                                       BeyazBulu≈üma     2\n",
       "6561                                              8Mart     2\n",
       "\n",
       "[6562 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labelize\n",
    "AKP=0\n",
    "CHP=1\n",
    "IYIP=2\n",
    "HDP=3\n",
    "akpscombined_df['label']='0'\n",
    "chpscombined_df['label']='1'\n",
    "hdpscombined_df['label']='3'\n",
    "iyipscombined_df['label']='2'\n",
    "iyipscombined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulkeninbasinabela = pd.concat([akpscombined_df, chpscombined_df, hdpscombined_df, iyipscombined_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nev≈üin Hocamƒ±z Sahura Doƒüru</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bastƒ±ƒüƒ±n yerleri toprak diyerek ge√ßme tanƒ±‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oy Erdoƒüan a oy Kƒ±zƒ±lelma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>se√ßim atmosferinde olacak bilmiyorum y√ºce Alla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Refah Partisi nin kararƒ±ndan sonra ya≈üadƒ±ƒüƒ±m o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27891</th>\n",
       "      <td>d√ºnya size kalmaz YiyinEfendilerYiyin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27892</th>\n",
       "      <td>H√ºr D√º≈ü√ºnce Hareketi y√∂netimi Gelecek Partisi ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27893</th>\n",
       "      <td>GeldikleriGibiGidecekler</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27894</th>\n",
       "      <td>BeyazBulu≈üma</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27895</th>\n",
       "      <td>8Mart</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27896 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet label\n",
       "0                            Nev≈üin Hocamƒ±z Sahura Doƒüru     0\n",
       "1            Bastƒ±ƒüƒ±n yerleri toprak diyerek ge√ßme tanƒ±‚Ä¶     0\n",
       "2                              oy Erdoƒüan a oy Kƒ±zƒ±lelma     0\n",
       "3      se√ßim atmosferinde olacak bilmiyorum y√ºce Alla...     0\n",
       "4      Refah Partisi nin kararƒ±ndan sonra ya≈üadƒ±ƒüƒ±m o...     0\n",
       "...                                                  ...   ...\n",
       "27891              d√ºnya size kalmaz YiyinEfendilerYiyin     2\n",
       "27892  H√ºr D√º≈ü√ºnce Hareketi y√∂netimi Gelecek Partisi ...     2\n",
       "27893                           GeldikleriGibiGidecekler     2\n",
       "27894                                       BeyazBulu≈üma     2\n",
       "27895                                              8Mart     2\n",
       "\n",
       "[27896 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulkeninbasinabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                              Nev≈üin Hocamƒ±z Sahura Doƒüru\n",
      "1              Bastƒ±ƒüƒ±n yerleri toprak diyerek ge√ßme tanƒ±‚Ä¶\n",
      "2                                oy Erdoƒüan a oy Kƒ±zƒ±lelma\n",
      "3        se√ßim atmosferinde olacak bilmiyorum y√ºce Alla...\n",
      "4        Refah Partisi nin kararƒ±ndan sonra ya≈üadƒ±ƒüƒ±m o...\n",
      "                               ...                        \n",
      "27891                d√ºnya size kalmaz YiyinEfendilerYiyin\n",
      "27892    H√ºr D√º≈ü√ºnce Hareketi y√∂netimi Gelecek Partisi ...\n",
      "27893                             GeldikleriGibiGidecekler\n",
      "27894                                         BeyazBulu≈üma\n",
      "27895                                                8Mart\n",
      "Name: tweet, Length: 27896, dtype: object\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "27891    2\n",
      "27892    2\n",
      "27893    2\n",
      "27894    2\n",
      "27895    2\n",
      "Name: label, Length: 27896, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Verilerin y√ºklenmesi\n",
    "\n",
    "# √ñzelliklerin ve etiketlerin ayrƒ±lmasƒ±\n",
    "X = ulkeninbasinabela['tweet']\n",
    "y = ulkeninbasinabela['label']\n",
    "\n",
    "\n",
    "X.shape\n",
    "y.shape\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3096, 6662, 10434, 12251, 16962, 21023]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eksikveri = ulkeninbasinabela.isna().any()\n",
    "eksikveri\n",
    "\n",
    "indeks = ulkeninbasinabela[ulkeninbasinabela.isna().any(axis=1)].index.tolist()\n",
    "z=ulkeninbasinabela.iloc[3095:3097]\n",
    "ulkeninbasinabela.drop\n",
    "z\n",
    "indeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulkeninbasinabela.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27890,)\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "27891    2\n",
      "27892    2\n",
      "27893    2\n",
      "27894    2\n",
      "27895    2\n",
      "Name: label, Length: 27890, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Verilerin y√ºklenmesi\n",
    "\n",
    "# √ñzelliklerin ve etiketlerin ayrƒ±lmasƒ±\n",
    "X = ulkeninbasinabela['tweet']\n",
    "y = ulkeninbasinabela['label']\n",
    "\n",
    "\n",
    "X.shape\n",
    "y.shape\n",
    "print(X.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4602007888131947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Verilerinizi eƒüitim ve test k√ºmelerine ayƒ±rƒ±n\n",
    "X_train, X_test, y_train, y_test = train_test_split(ulkeninbasinabela['tweet'], ulkeninbasinabela['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# CountVectorizer kullanarak metin verilerinizi sayƒ±sal √∂zelliklere d√∂n√º≈üt√ºr√ºn\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# KNN modelinizi eƒüitin\n",
    "k = 5 # K sayƒ±sƒ±\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Test k√ºmesindeki verileri kullanarak modelinizi deƒüerlendirin\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Verilerinizi eƒüitim ve test k√ºmelerine ayƒ±rƒ±n\n",
    "X_train, X_test, y_train, y_test = train_test_split(ulkeninbasinabela['tweet'], ulkeninbasinabela['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# CountVectorizer kullanarak metin verilerinizi sayƒ±sal √∂zelliklere d√∂n√º≈üt√ºr√ºn\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# KNN modelinizi eƒüitin\n",
    "k = 5 # K sayƒ±sƒ±\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Test k√ºmesindeki verileri kullanarak modelinizi deƒüerlendirin\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yerli ve milli iha -> 1\n",
      "akp senin amk  -> 0\n",
      "Genel Ba≈ükanƒ±mƒ±z Sn Meral Ak≈üener katƒ±lacaƒüƒ± 3 Olaƒüan ƒ∞l Kongremize sizleri bekliyoruz  -> 2\n"
     ]
    }
   ],
   "source": [
    "# Test verilerinin sƒ±nƒ±flandƒ±rƒ±lmasƒ±\n",
    "test_text = ['yerli ve milli iha', 'akp senin amk ', 'Genel Ba≈ükanƒ±mƒ±z Sn Meral Ak≈üener katƒ±lacaƒüƒ± 3 Olaƒüan ƒ∞l Kongremize sizleri bekliyoruz ']\n",
    "test_features = vectorizer.transform(test_text)\n",
    "predictions = knn.predict(test_features)\n",
    "\n",
    "# Sonu√ßlarƒ±n yazdƒ±rƒ±lmasƒ±\n",
    "for i, text in enumerate(test_text):\n",
    "    print(f\"{text} -> {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6052348512011474\n"
     ]
    }
   ],
   "source": [
    "# Gerekli k√ºt√ºphanelerin y√ºklenmesi\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "X = ulkeninbasinabela['tweet']\n",
    "y = ulkeninbasinabela['label']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vekt√∂rle≈ütirme i≈ülemi\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# SVM modelinin eƒüitilmesi\n",
    "svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"svm\", NuSVC(kernel=\"rbf\", gamma=\"auto\"))\n",
    "])\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Test veri k√ºmesi √ºzerinde tahmin yapƒ±lmasƒ±\n",
    "y_pred = svm.predict(X_test)\n",
    "# Test veri k√ºmesi √ºzerinde tahmin yapƒ±lmasƒ±\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Model performansƒ±nƒ±n √∂l√ß√ºlmesi\n",
    "NuSVC_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"NuSVC_accuracy:\", NuSVC_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savunma sanayimiz cok iyi yegenim   -> 2\n",
      "akp senin amk  rte ol serefsiz  -> 0\n",
      "Meral annem   -> 0\n",
      "rojava direnisi  -> 3\n",
      "Katil Tc  -> 0\n"
     ]
    }
   ],
   "source": [
    "# Test verilerinin sƒ±nƒ±flandƒ±rƒ±lmasƒ±\n",
    "test_text = ['savunma sanayimiz cok iyi yegenim  ', 'akp senin amk  rte ol serefsiz ', 'Meral annem  ','rojava direnisi ', 'Katil Tc ']\n",
    "test_features = vectorizer.transform(test_text)\n",
    "predictions = svm.predict(test_features)\n",
    "\n",
    "# Sonu√ßlarƒ±n yazdƒ±rƒ±lmasƒ±\n",
    "for i, text in enumerate(test_text):\n",
    "    print(f\"{text} -> {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5166726425242022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X = ulkeninbasinabela['tweet']\n",
    "y = ulkeninbasinabela['label']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vekt√∂rle≈ütirme i≈ülemi\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", gamma=\"auto\"))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"rbf_accuracy:\", rbf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly_accuracy: 0.651846539978487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vekt√∂rle≈ütirme i≈ülemi\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"svm\", SVC(kernel=\"poly\", degree=3, coef0=1, gamma=\"auto\"))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "poly_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"poly_accuracy:\", poly_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vekt√∂rle≈ütirme i≈ülemi\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"linear\"))\n",
    "])\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.7133381140193618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vec, y_train)\n",
    "y_pred = nb.predict(X_train_vec)\n",
    "nb_accuracy = nb.score(X_test_vec, y_test)\n",
    "print(\"Naive Bayes accuracy:\", nb_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savunma sanayimiz cok iyi yegenim   -> 0\n",
      "Ey buyuk Ataturk  -> 1\n",
      "akp senin amk,  rte ol serefsiz  -> 2\n",
      "rojava direnisinin 10.yil donumu  -> 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# accuracy: 0.7133381140193618\n",
    "\n",
    "\n",
    "test_text = ['savunma sanayimiz cok iyi yegenim  ','Ey buyuk Ataturk ', 'akp senin amk,  rte ol serefsiz ','rojava direnisinin 10.yil donumu ']\n",
    "test_features = vectorizer.transform(test_text)\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Sonu√ßlarƒ±n yazdƒ±rƒ±lmasƒ±\n",
    "for i, text in enumerate(test_text):\n",
    "    print(f\"{text} -> {predictions[i]}\")\n",
    "\n",
    "#AKP=0\n",
    "#CHP=1\n",
    "#IYIP=2\n",
    "#HDP=3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saka bi yana kk ve rte disinda benim oy verme sebebim sizin gibi insaanlari bi kaliba sokma cabalariniz -> 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# accuracy: 0.7133381140193618\n",
    "\n",
    "\n",
    "test_text = ['saka bi yana kk ve rte disinda benim oy verme sebebim sizin gibi insaanlari bi kaliba sokma cabalariniz']\n",
    "test_features = vectorizer.transform(test_text)\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Sonu√ßlarƒ±n yazdƒ±rƒ±lmasƒ±\n",
    "for i, text in enumerate(test_text):\n",
    "    print(f\"{text} -> {predictions[i]}\")\n",
    "\n",
    "#AKP=0\n",
    "#CHP=1\n",
    "#IYIP=2\n",
    "#HDP=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.6306920043026174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_train)\n",
    "nb_accuracy = nb.score(X_test, y_test)\n",
    "print(\"Naive Bayes accuracy with tfidf:\", nb_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savunma sanayimiz cok iyi yegenim   -> 3\n",
      "akp senin amk  rte ol serefsiz  -> 2\n",
      "Meral annem   -> 2\n",
      "rojava direnisi  -> 3\n",
      "Katil Tc  -> 0\n"
     ]
    }
   ],
   "source": [
    "test_text = ['savunma sanayimiz cok iyi yegenim  ', 'akp senin amk  rte ol serefsiz ', 'Meral annem  ','rojava direnisi ', 'Katil Tc ']\n",
    "test_features = vectorizer.transform(test_text)\n",
    "predictions = svm.predict(test_features)\n",
    "\n",
    "# Sonu√ßlarƒ±n yazdƒ±rƒ±lmasƒ±\n",
    "for i, text in enumerate(test_text):\n",
    "    print(f\"{text} -> {predictions[i]}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKP=0\n",
    "CHP=1\n",
    "IYIP=2\n",
    "HDP=3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
